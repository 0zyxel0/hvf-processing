{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15109,
     "status": "ok",
     "timestamp": 1743779651505,
     "user": {
      "displayName": "Mitch",
      "userId": "13417906856348736634"
     },
     "user_tz": -120
    },
    "id": "nwA3uCSQSDkV",
    "outputId": "870c7a2e-dc9d-4813-bb3b-3815f448cf9a"
   },
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 707,
     "status": "ok",
     "timestamp": 1743779665145,
     "user": {
      "displayName": "Mitch",
      "userId": "13417906856348736634"
     },
     "user_tz": -120
    },
    "id": "3PdqVrLfSL0R"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1743779679223,
     "user": {
      "displayName": "Mitch",
      "userId": "13417906856348736634"
     },
     "user_tz": -120
    },
    "id": "BH75kYjcTwT0"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_year_period_week(filename):\n",
    "    \"\"\"Extracts year, period, and week from a filename like '2024_p1_w1.csv'.\n",
    "\n",
    "    Args:\n",
    "        filename: The name of the file.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing the year, period, and week as integers.\n",
    "    \"\"\"\n",
    "    match = re.search(r\"(\\d+)_p(\\d+)_w(\\d+)\", filename)\n",
    "    if match:\n",
    "        year = int(match.group(1))\n",
    "        period = int(match.group(2))\n",
    "        week = int(match.group(3))\n",
    "        return year, period, week\n",
    "    else:\n",
    "        return None, None, None  # Handle cases where the pattern is not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1743779767984,
     "user": {
      "displayName": "Mitch",
      "userId": "13417906856348736634"
     },
     "user_tz": -120
    },
    "id": "EzhBnE2dT3M7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for filename in ['2024_p7_w3.csv']:\n",
    "    df = pd.read_csv(filename, dtype={'GROWER': str, 'TERRAIN': str})\n",
    "    year, period, week = extract_year_period_week(filename)\n",
    "\n",
    "    if year is not None and period is not None and week is not None:\n",
    "        df['year'] = year  # Add 'Year' column\n",
    "        df['period'] = period  # Add 'Period' column\n",
    "        df['week'] = week  # Add 'Week' column\n",
    "    else:\n",
    "        print(f\"Warning: Could not extract year, period, and week from {filename}\")\n",
    "\n",
    "    # Process the DataFrame further..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1743779915026,
     "user": {
      "displayName": "Mitch",
      "userId": "13417906856348736634"
     },
     "user_tz": -120
    },
    "id": "7MxJHvfYKHAV"
   },
   "outputs": [],
   "source": [
    "def rename_csv_files(directory):\n",
    "  \"\"\"Renames CSV files in a directory from 'p{period}_w{week}.csv' to 'processed_p{period}_w{week}.csv'.\n",
    "\n",
    "  Args:\n",
    "    directory: The directory containing the CSV files.\n",
    "  \"\"\"\n",
    "  for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\") and filename.startswith(\"p\"):\n",
    "      base_name = os.path.splitext(filename)[0]  # Get filename without extension\n",
    "      period, week = base_name[1:].split(\"_\")  # Extract period and week\n",
    "      new_filename = f\"processed_{period}_{week}.csv\"\n",
    "      os.rename(os.path.join(directory, filename), os.path.join(directory, new_filename))\n",
    "      print(f\"Renamed '{filename}' to '{new_filename}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This part is a merged code to put all data to a pandas dataframe and load it to RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def extract_year_period_week(filename):\n",
    "    \"\"\"Extracts year, period, and week from a filename like '2024_p1_w1.csv'.\n",
    "\n",
    "    Args:\n",
    "        filename: The name of the file.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing the year, period, and week as integers.\n",
    "    \"\"\"\n",
    "    match = re.search(r\"(\\d+)_p(\\d+)_w(\\d+)\", filename)\n",
    "    if match:\n",
    "        year = int(match.group(1))\n",
    "        period = int(match.group(2))\n",
    "        week = int(match.group(3))\n",
    "        return year, period, week\n",
    "    else:\n",
    "        return None, None, None  # Handle cases where the pattern is not found\n",
    "\n",
    "def process_csv_files(directory):\n",
    "    \"\"\"Processes all CSV files in a directory, ingests data into a pandas DataFrame, and melts the DataFrame.\n",
    "\n",
    "    Args:\n",
    "        directory: The directory containing the CSV files.\n",
    "\n",
    "    Returns:\n",
    "        A pandas DataFrame containing the melted data from all CSV files.\n",
    "    \"\"\"\n",
    "    all_data = []  # List to store data from all files\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".csv\") and filename.startswith(\"20\"):  # Process only CSV files starting with \"20\"\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            df = pd.read_csv(filepath, dtype={'GROWER': str, 'TERRAIN': str})\n",
    "            \n",
    "            year, period, week = extract_year_period_week(filename)\n",
    "            if year is not None and period is not None and week is not None:\n",
    "                df['year'] = year  # Add 'Year' column\n",
    "                df['period'] = period  # Add 'Period' column\n",
    "                df['week'] = week  # Add 'Week' column\n",
    "            else:\n",
    "                print(f\"Warning: Could not extract year, period, and week from {filename}\")\n",
    "\n",
    "            # Melt the DataFrame\n",
    "            melted_df = pd.melt(df,\n",
    "                               id_vars=['GROWER', 'TERRAIN', 'BAGGING', 'STEMS', 'KLS.A', 'BXS.A', 'KLS.B', 'BXS.B', 'startdate', 'enddate', 'year', 'period', 'week'],\n",
    "                               value_vars=['WK_10', 'WK_11', 'WK_12', 'WK_13', 'WK_14', 'WK_15', 'WK_16', 'WK_17'],\n",
    "                               var_name='Week_Name',\n",
    "                               value_name='stem_harvest_week_count')\n",
    "\n",
    "            all_data.append(melted_df)  # Append melted data to the list\n",
    "\n",
    "    # Concatenate all data into a single DataFrame\n",
    "    final_df = pd.concat(all_data, ignore_index=True)\n",
    "    return final_df\n",
    "\n",
    "# Example usage:\n",
    "directory_path = './data'  # Replace with the actual directory path\n",
    "final_df = process_csv_files(directory_path)\n",
    "final_df.head()\n",
    "# Now you have the final_df containing data from all CSV files in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm \n",
    "# Replace with your Strapi API endpoint for creating entries\n",
    "strapi_api_endpoint = \"http://127.0.0.1:1337/api/harvests\"\n",
    "\n",
    "def format_date(date_str):\n",
    "  \"\"\"Formats a date string from 'dd-mm-yyyy' to 'yyyy-MM-dd'.\n",
    "\n",
    "  Args:\n",
    "    date_str: The date string in 'dd-mm-yyyy' format.\n",
    "\n",
    "  Returns:\n",
    "    The formatted date string in 'yyyy-MM-dd' format.\n",
    "  \"\"\"\n",
    "  return pd.to_datetime(date_str, format='%d-%m-%Y').strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "# Iterate through the rows of the final_df\n",
    "for index, row in tqdm(final_df.iterrows(), total=final_df.shape[0]):  \n",
    "  # Create a dictionary with the data for your Strapi content type\n",
    "  data = { \"data\":{\n",
    "      \"grower\": row[\"GROWER\"],\n",
    "      \"terrainid\": row[\"TERRAIN\"],\n",
    "      \"bagging\": row[\"BAGGING\"],\n",
    "      \"stems\": row[\"STEMS\"],\n",
    "      \"class_type_a\": row[\"KLS.A\"],\n",
    "      \"box_type_a\": row[\"BXS.A\"],\n",
    "      \"class_type_b\": row[\"KLS.B\"],\n",
    "      \"box_type_b\": row[\"BXS.B\"],\n",
    "      \"stem_harvest_week\": row[\"Week_Name\"],\n",
    "      \"stem_harvest_count\": row[\"stem_harvest_week_count\"],\n",
    "      \"startdate\": format_date(row[\"startdate\"]),\n",
    "      \"enddate\": format_date(row[\"enddate\"]),\n",
    "      \"period\": int(row[\"period\"]),\n",
    "      \"week\": int(row[\"week\"]),\n",
    "      \"year\": str(row[\"year\"]),\n",
    "      # Add other fields as needed\n",
    "  }}  \n",
    " \n",
    "  try:\n",
    "   # Convert data to JSON string with double quotes\n",
    "    json_data = json.dumps(data)  \n",
    "    print(f\"Sending Data : {json_data}\")\n",
    "    # Make POST request with the JSON string\n",
    "    response = requests.post(strapi_api_endpoint, data=json_data, headers={'Content-Type': 'application/json'})\n",
    "\n",
    "    response.raise_for_status()\n",
    "    print(f\"Successfully created entry for row {index}\")    \n",
    "  except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error creating entry for row {index}: {e}\")\n",
    "  time.sleep(.5)  # Wait for 1 second before processing the next row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We then save to csv the processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"2024_production_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
