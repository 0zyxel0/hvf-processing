{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15109,
     "status": "ok",
     "timestamp": 1743779651505,
     "user": {
      "displayName": "Mitch",
      "userId": "13417906856348736634"
     },
     "user_tz": -120
    },
    "id": "nwA3uCSQSDkV",
    "outputId": "870c7a2e-dc9d-4813-bb3b-3815f448cf9a"
   },
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 707,
     "status": "ok",
     "timestamp": 1743779665145,
     "user": {
      "displayName": "Mitch",
      "userId": "13417906856348736634"
     },
     "user_tz": -120
    },
    "id": "3PdqVrLfSL0R"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1743779679223,
     "user": {
      "displayName": "Mitch",
      "userId": "13417906856348736634"
     },
     "user_tz": -120
    },
    "id": "BH75kYjcTwT0"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_year_period_week(filename):\n",
    "    \"\"\"Extracts year, period, and week from a filename like '2024_p1_w1.csv'.\n",
    "\n",
    "    Args:\n",
    "        filename: The name of the file.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing the year, period, and week as integers.\n",
    "    \"\"\"\n",
    "    match = re.search(r\"(\\d+)_p(\\d+)_w(\\d+)\", filename)\n",
    "    if match:\n",
    "        year = int(match.group(1))\n",
    "        period = int(match.group(2))\n",
    "        week = int(match.group(3))\n",
    "        return year, period, week\n",
    "    else:\n",
    "        return None, None, None  # Handle cases where the pattern is not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1743779767984,
     "user": {
      "displayName": "Mitch",
      "userId": "13417906856348736634"
     },
     "user_tz": -120
    },
    "id": "EzhBnE2dT3M7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for filename in ['2024_p7_w3.csv']:\n",
    "    df = pd.read_csv(filename, dtype={'GROWER': str, 'TERRAIN': str})\n",
    "    year, period, week = extract_year_period_week(filename)\n",
    "\n",
    "    if year is not None and period is not None and week is not None:\n",
    "        df['year'] = year  # Add 'Year' column\n",
    "        df['period'] = period  # Add 'Period' column\n",
    "        df['week'] = week  # Add 'Week' column\n",
    "    else:\n",
    "        print(f\"Warning: Could not extract year, period, and week from {filename}\")\n",
    "\n",
    "    # Process the DataFrame further..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 342
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1743779773740,
     "user": {
      "displayName": "Mitch",
      "userId": "13417906856348736634"
     },
     "user_tz": -120
    },
    "id": "S-67uS-ITapE",
    "outputId": "2abd3a08-660c-4884-fa13-0c4a4e2e6b39"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 84,
     "status": "ok",
     "timestamp": 1743779860634,
     "user": {
      "displayName": "Mitch",
      "userId": "13417906856348736634"
     },
     "user_tz": -120
    },
    "id": "5ILnosGpzbiy",
    "outputId": "b2c9c93c-e209-4a05-9a16-0dc6cdd4a571"
   },
   "outputs": [],
   "source": [
    "melted_df = pd.melt(df,\n",
    "                   id_vars=['GROWER',\n",
    "                             'TERRAIN',\n",
    "                             'BAGGING',\n",
    "                             'STEMS',\n",
    "                             'KLS.A',\n",
    "                             'BXS.A',\n",
    "                             'KLS.B',\n",
    "                             'BXS.B',\n",
    "                            'startdate','enddate','year','period','week'],\n",
    "                   value_vars=['WK_10', 'WK_11', 'WK_12', 'WK_13',\n",
    "                               'WK_14', 'WK_15', 'WK_16', 'WK_17'],\n",
    "                   var_name='Week_Name',\n",
    "                   value_name='stem_harvest_week_count')\n",
    "\n",
    "display(melted_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1743779915026,
     "user": {
      "displayName": "Mitch",
      "userId": "13417906856348736634"
     },
     "user_tz": -120
    },
    "id": "7MxJHvfYKHAV"
   },
   "outputs": [],
   "source": [
    "def rename_csv_files(directory):\n",
    "  \"\"\"Renames CSV files in a directory from 'p{period}_w{week}.csv' to 'processed_p{period}_w{week}.csv'.\n",
    "\n",
    "  Args:\n",
    "    directory: The directory containing the CSV files.\n",
    "  \"\"\"\n",
    "  for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\") and filename.startswith(\"p\"):\n",
    "      base_name = os.path.splitext(filename)[0]  # Get filename without extension\n",
    "      period, week = base_name[1:].split(\"_\")  # Extract period and week\n",
    "      new_filename = f\"processed_{period}_{week}.csv\"\n",
    "      os.rename(os.path.join(directory, filename), os.path.join(directory, new_filename))\n",
    "      print(f\"Renamed '{filename}' to '{new_filename}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 86,
     "status": "ok",
     "timestamp": 1743084049427,
     "user": {
      "displayName": "Mitch",
      "userId": "13417906856348736634"
     },
     "user_tz": -60
    },
    "id": "XR837RSYFowi",
    "outputId": "09294802-b1fa-4c20-f00e-b3208171b971"
   },
   "outputs": [],
   "source": [
    "# prompt: from the melted_df, i would need to insert the data from each row to my strapi cms using a http post request\n",
    "\n",
    "# Replace with your Strapi API endpoint for creating entries\n",
    "strapi_api_endpoint = \"http://127.0.0.1:1337/api/harvests\"\n",
    "\n",
    "# Iterate through the rows of the melted_df\n",
    "for index, row in melted_df.iterrows():\n",
    "  # Create a dictionary with the data for your Strapi content type\n",
    "  data = { \"data\":{\n",
    "      \"grower\": row[\"GROWER\"],\n",
    "      \"terrainid\": row[\"TERRAIN\"],\n",
    "      \"bagging\": row[\"BAGGING\"],\n",
    "      \"stems\": row[\"STEMS\"],\n",
    "      \"class_type_a\": row[\"KLS.A\"],\n",
    "      \"box_type_a\": row[\"BXS.A\"],\n",
    "      \"class_type_b\": row[\"KLS.B\"],\n",
    "      \"box_type_b\": row[\"BXS.B\"],\n",
    "      \"stem_harvest_week\": row[\"Week_Name\"],\n",
    "      \"stem_harvest_count\": row[\"stem_harvest_week_count\"],\n",
    "      \"startdate\": row[\"startdate\"],\n",
    "      \"enddate\": row[\"enddate\"],\n",
    "      \"period\": row[\"period\"],\n",
    "      \"week\": row[\"week\"],\n",
    "      \"year\": row[\"year\"],\n",
    "      # Add other fields as needed\n",
    "  }}\n",
    "  print(data)\n",
    "  try:\n",
    "    # Make a POST request to your Strapi API\n",
    "    response = requests.post(strapi_api_endpoint, json=data)\n",
    "    response.raise_for_status()  # Raise an exception for bad status codes\n",
    "\n",
    "    print(f\"Successfully created entry for row {index}: {response.json()}\")\n",
    "\n",
    "  except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error creating entry for row {index}: {e}\")\n",
    "  time.sleep(.3)  # Wait for 1 second before processing the next row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_NDfodKg6H4r"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b019b5Ga2coY"
   },
   "outputs": [],
   "source": [
    "# prompt: from the melted_df save it to a csv\n",
    "new_filename = f'processed_{file_name.split('_')[0][1]}_{file_name.split('_')[1].split('.')[0][1]}.csv'\n",
    "melted_df.to_csv(new_filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is a merged code to put all data to a pandas dataframe and load it to RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def extract_year_period_week(filename):\n",
    "    \"\"\"Extracts year, period, and week from a filename like '2024_p1_w1.csv'.\n",
    "\n",
    "    Args:\n",
    "        filename: The name of the file.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing the year, period, and week as integers.\n",
    "    \"\"\"\n",
    "    match = re.search(r\"(\\d+)_p(\\d+)_w(\\d+)\", filename)\n",
    "    if match:\n",
    "        year = int(match.group(1))\n",
    "        period = int(match.group(2))\n",
    "        week = int(match.group(3))\n",
    "        return year, period, week\n",
    "    else:\n",
    "        return None, None, None  # Handle cases where the pattern is not found\n",
    "\n",
    "def process_csv_files(directory):\n",
    "    \"\"\"Processes all CSV files in a directory, ingests data into a pandas DataFrame, and melts the DataFrame.\n",
    "\n",
    "    Args:\n",
    "        directory: The directory containing the CSV files.\n",
    "\n",
    "    Returns:\n",
    "        A pandas DataFrame containing the melted data from all CSV files.\n",
    "    \"\"\"\n",
    "    all_data = []  # List to store data from all files\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".csv\") and filename.startswith(\"20\"):  # Process only CSV files starting with \"20\"\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            df = pd.read_csv(filepath, dtype={'GROWER': str, 'TERRAIN': str})\n",
    "            \n",
    "            year, period, week = extract_year_period_week(filename)\n",
    "            if year is not None and period is not None and week is not None:\n",
    "                df['year'] = year  # Add 'Year' column\n",
    "                df['period'] = period  # Add 'Period' column\n",
    "                df['week'] = week  # Add 'Week' column\n",
    "            else:\n",
    "                print(f\"Warning: Could not extract year, period, and week from {filename}\")\n",
    "\n",
    "            # Melt the DataFrame\n",
    "            melted_df = pd.melt(df,\n",
    "                               id_vars=['GROWER', 'TERRAIN', 'BAGGING', 'STEMS', 'KLS.A', 'BXS.A', 'KLS.B', 'BXS.B', 'startdate', 'enddate', 'year', 'period', 'week'],\n",
    "                               value_vars=['WK_10', 'WK_11', 'WK_12', 'WK_13', 'WK_14', 'WK_15', 'WK_16', 'WK_17'],\n",
    "                               var_name='Week_Name',\n",
    "                               value_name='stem_harvest_week_count')\n",
    "\n",
    "            all_data.append(melted_df)  # Append melted data to the list\n",
    "\n",
    "    # Concatenate all data into a single DataFrame\n",
    "    final_df = pd.concat(all_data, ignore_index=True)\n",
    "    return final_df\n",
    "\n",
    "# Example usage:\n",
    "directory_path = './data'  # Replace with the actual directory path\n",
    "final_df = process_csv_files(directory_path)\n",
    "final_df.head()\n",
    "# Now you have the final_df containing data from all CSV files in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GROWER</th>\n",
       "      <th>TERRAIN</th>\n",
       "      <th>BAGGING</th>\n",
       "      <th>STEMS</th>\n",
       "      <th>KLS.A</th>\n",
       "      <th>BXS.A</th>\n",
       "      <th>KLS.B</th>\n",
       "      <th>BXS.B</th>\n",
       "      <th>startdate</th>\n",
       "      <th>enddate</th>\n",
       "      <th>year</th>\n",
       "      <th>period</th>\n",
       "      <th>week</th>\n",
       "      <th>Week_Name</th>\n",
       "      <th>stem_harvest_week_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A. NOEL</td>\n",
       "      <td>0304</td>\n",
       "      <td>209</td>\n",
       "      <td>149.0</td>\n",
       "      <td>2871.04</td>\n",
       "      <td>214.26</td>\n",
       "      <td>202.37</td>\n",
       "      <td>15.10</td>\n",
       "      <td>02-12-2024</td>\n",
       "      <td>07-12-2024</td>\n",
       "      <td>2024</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>WK_10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RABIA</td>\n",
       "      <td>0304</td>\n",
       "      <td>49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>02-12-2024</td>\n",
       "      <td>07-12-2024</td>\n",
       "      <td>2024</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>WK_10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALVAREZ, E.</td>\n",
       "      <td>0006</td>\n",
       "      <td>172</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1056.50</td>\n",
       "      <td>78.84</td>\n",
       "      <td>11.02</td>\n",
       "      <td>0.82</td>\n",
       "      <td>02-12-2024</td>\n",
       "      <td>07-12-2024</td>\n",
       "      <td>2024</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>WK_10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ONGKINGCO, J.</td>\n",
       "      <td>0013</td>\n",
       "      <td>110</td>\n",
       "      <td>107.0</td>\n",
       "      <td>2108.69</td>\n",
       "      <td>157.36</td>\n",
       "      <td>38.50</td>\n",
       "      <td>2.87</td>\n",
       "      <td>02-12-2024</td>\n",
       "      <td>07-12-2024</td>\n",
       "      <td>2024</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>WK_10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>REYES, P.</td>\n",
       "      <td>0027</td>\n",
       "      <td>67</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1159.98</td>\n",
       "      <td>86.57</td>\n",
       "      <td>39.62</td>\n",
       "      <td>2.96</td>\n",
       "      <td>02-12-2024</td>\n",
       "      <td>07-12-2024</td>\n",
       "      <td>2024</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>WK_10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          GROWER TERRAIN  BAGGING  STEMS    KLS.A   BXS.A   KLS.B  BXS.B  \\\n",
       "0        A. NOEL    0304      209  149.0  2871.04  214.26  202.37  15.10   \n",
       "1         RABIA     0304       49    0.0     0.00    0.00    0.00   0.00   \n",
       "2    ALVAREZ, E.    0006      172   51.0  1056.50   78.84   11.02   0.82   \n",
       "3  ONGKINGCO, J.    0013      110  107.0  2108.69  157.36   38.50   2.87   \n",
       "4      REYES, P.    0027       67   56.0  1159.98   86.57   39.62   2.96   \n",
       "\n",
       "    startdate     enddate  year  period  week Week_Name  \\\n",
       "0  02-12-2024  07-12-2024  2024      10     1     WK_10   \n",
       "1  02-12-2024  07-12-2024  2024      10     1     WK_10   \n",
       "2  02-12-2024  07-12-2024  2024      10     1     WK_10   \n",
       "3  02-12-2024  07-12-2024  2024      10     1     WK_10   \n",
       "4  02-12-2024  07-12-2024  2024      10     1     WK_10   \n",
       "\n",
       "   stem_harvest_week_count  \n",
       "0                      0.0  \n",
       "1                      0.0  \n",
       "2                      0.0  \n",
       "3                      0.0  \n",
       "4                      0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
